{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab_XLNet_FineTuning",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-malte/Colab-XLNet-FineTuning/blob/master/Colab_XLNet_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhdjgZWAZ60C",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meO7ZaISZfZ1",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQH4OCHZ9bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyg_OpLWAKhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install dependencies\n",
        "!pip install emoji\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXG1d-yWHcPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install dependencies\n",
        "import os\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import pandas as pd  \n",
        "import subprocess\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G_iOF7gLpNXb"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "###Pull XLNet Repo for given task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxguVChxp2fI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "git_url = \"https://github.com/aditya-malte/Colab-XLNet-FineTuning.git\"  #@param {type:\"string\"}\n",
        "os.system(\"git clone \"+git_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgpISXC_Ax_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git pull origin master\n",
        "#Use if you have updated git repo and want changes to reflect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW8k3tDRTndN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "repo_name = 'Colab-XLNet-FineTuning' #@param {type:\"string\"}\n",
        "%ls\n",
        "%cd {repo_name}\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTLZ3I4_7c_",
        "colab_type": "text"
      },
      "source": [
        "# XLNet End to End (Fine-tuning + Evaluation) in 5 minutes with Cloud TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wtjs1QDb3DX",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "\n",
        "This Colab demonstates using a free Colab Cloud TPU to fine-tune sentence and sentence-pair classification tasks built on top of pretrained XLNet models and \n",
        "run predictions on tuned model. The colab demonsrates loading pretrained BERT models from both [TF Hub](https://www.tensorflow.org/hub) and checkpoints.\n",
        "\n",
        "**Note:**  You will need a GCP (Google Compute Engine) account and a GCS (Google Cloud \n",
        "Storage) bucket for this Colab to run.\n",
        "\n",
        "Please follow the [Google Cloud TPU quickstart](https://cloud.google.com/tpu/docs/quickstart) for how to create GCP account and GCS bucket. You have [$300 free credit](https://cloud.google.com/free/) to get started with any GCP product. You can learn more about Cloud TPU at https://cloud.google.com/tpu/docs.\n",
        "\n",
        "This notebook is hosted on GitHub. To view it in its original repository, after opening the notebook, select **File > View on GitHub**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld-JXlueIuPH",
        "colab_type": "text"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkof5uHaQ_c",
        "colab_type": "text"
      },
      "source": [
        "<h3><a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Train on TPU</h3>\n",
        "\n",
        "   1. Create a Cloud Storage bucket for your TensorBoard logs at http://console.cloud.google.com/storage and fill in the BUCKET parameter in the \"Parameters\" section below.\n",
        " \n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All** (Watch out: the \"Colab-only auth for this notebook and the TPU\" cell requires user input). You can also run the cells manually with Shift-ENTER."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdMmwCJFaT8F",
        "colab_type": "text"
      },
      "source": [
        "### Set up your TPU environment\n",
        "\n",
        "In this section, you perform the following tasks:\n",
        "\n",
        "*   Set up a Colab TPU running environment\n",
        "*   Verify that you are connected to a TPU device\n",
        "*   Upload your credentials to TPU to access your GCS bucket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191zq3ZErihP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "print(os.environ)\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRu1aKO1D7-Z",
        "colab_type": "text"
      },
      "source": [
        "### Prepare for training\n",
        "\n",
        "This next section of code performs the following tasks:\n",
        "\n",
        "*  Specify task and download training data.\n",
        "*  Specify BERT pretrained model\n",
        "*  Specify GS bucket, create output directory for model checkpoints and eval results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYkaAlJNfhul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TASK = 'TASK_NAME' #@param {type:\"string\"}\n",
        "\n",
        "TASK_DATA_DIR = 'DIRECTORY' #@param {type:\"string\"}\n",
        "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "!ls $TASK_DATA_DIR\n",
        "\n",
        "BUCKET = 'BUCKET_NAME' #@param {type:\"string\"}\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/xlnet/output/{}'.format(BUCKET, TASK)\n",
        "MODEL_DIR = 'gs://{}/xlnet/model/{}'..format(BUCKET, TASK)\n",
        "\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "tf.gfile.MakeDirs(MODEL_DIR)\n",
        "\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcpfl4N2EdOk",
        "colab_type": "text"
      },
      "source": [
        "Now let's load tokenizer module from TF Hub and play with it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqQ_LHyzcoYW",
        "colab_type": "text"
      },
      "source": [
        "Also we initilize our hyperprams, prepare the training data and initialize TPU config."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7eW79mM8Qdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.system(\"wget https://storage.googleapis.com/xlnet/released_models/cased_L-24_H-1024_A-16.zip\")\n",
        "os.system(\"unzip cased_L-24_H-1024_A-16.zip\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpofnyuR_sYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd xlnet_cased_L-24_H-1024_A-16\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6STFA7rYyStw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_names = os.listdir(os.getcwd())\n",
        "print(file_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtzjAQT6wZbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file_name in file_names:\n",
        "  print(file_name)\n",
        "  os.system(\"gsutil cp \"+ file_name + \" \" + OUTPUT_DIR)\n",
        "os.system(\"gsutil ls \" + OUTPUT_DIR)\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn6ljng_B-EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.system(\"gsutil cp -r \" + MODEL_DIR + \"/spiece.model spiece.model\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vinj3p_X96ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BATCH_SIZE = 64\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_STEPS = 1200\n",
        "MAX_SEQ_LENGTH = 128 \n",
        "# Warmup is a period of time where the learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_STEPS = 120\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 1200\n",
        "NUM_ITERATIONS = 1200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kyacr8InG8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "command = \"python run_classifier.py \\\n",
        "  --use_tpu=True \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --eval_all_ckpt=True \\\n",
        "  --task_name=\"+TASK.lower()+\" \\\n",
        "  --data_dir=./\"+TASK_DATA_DIR+\" \\\n",
        "  --output_dir=\"+OUTPUT_DIR+\" \\\n",
        "  --model_dir=\"+MODEL_DIR+\" \\\n",
        "  --uncased=False \\\n",
        "  --tpu_address=\"+TPU_ADDRESS+\"  \\\n",
        "  --spiece_model_file=./spiece.model \\\n",
        "  --model_config_path=\"+MODEL_DIR+\"/xlnet_config.json \\\n",
        "  --init_checkpoint=\"+MODEL_DIR+\"/xlnet_model.ckpt \\\n",
        "  --max_seq_length=\"+str(MAX_SEQ_LENGTH)+\" \\\n",
        "  --train_batch_size=\"+str(TRAIN_BATCH_SIZE)+\" \\\n",
        "  --eval_batch_size=\"+str(EVAL_BATCH_SIZE)+\" \\\n",
        "  --num_hosts=1 \\\n",
        "  --num_core_per_host=8 \\\n",
        "  --learning_rate=2e-5 \\\n",
        "  --train_steps=\"+str(NUM_TRAIN_STEPS)+\" \\\n",
        "  --warmup_steps=\"+str(WARMUP_STEPS)+\" \\\n",
        "  --save_steps=\"+str(SAVE_CHECKPOINTS_STEPS)+\" \\\n",
        "  --iterations=\"+ str(NUM_ITERATIONS)\n",
        "\n",
        "print(command)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX2y2tQcMJ3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!{command}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}